# Gesture-Motion-MiDOG
Controlling of a MiDog (small quadraped) robot using the Hand Gestures detected by a Neural Network.

A neural network is trained on the basic gestures of the hand that are linked to the robot's actions (E.g., sit, walk forward, walk sideward, greet, etc.). For this, the RPi camera on the robot is used. This network is then used to control the robot in real time by performing actions. The use case considered for this project is in the construction industry. 
Often, the workers carry multiple things/objects and need to get objects from one place to another. Sometimes, they are occupied and need to get a tool that is placed a bit far away. In this case, the person can signal the robot the preddefined gesture and it will get the object.
